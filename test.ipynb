{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbYXou6chZf",
    "outputId": "cf134be8-5ad0-4d1b-fb35-9101af16f166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  9 13:17:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUEL020u0-O8"
   },
   "outputs": [],
   "source": [
    "pip install regex requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yWfnuPMa1A6G"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import importlib\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M46ShGdA1A3U"
   },
   "outputs": [],
   "source": [
    " pip install hydra-core --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0sfwJqaY1A1X"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import importlib\n",
    "\n",
    "\n",
    "dependencies = [\n",
    "    \"dataclasses\",\n",
    "    \"hydra\",\n",
    "    \"numpy\",\n",
    "    \"omegaconf\",\n",
    "    \"regex\",\n",
    "    \"requests\",\n",
    "    \"torch\",\n",
    "]\n",
    "\n",
    "\n",
    "missing_deps = []\n",
    "for dep in dependencies:\n",
    "    try:\n",
    "        importlib.import_module(dep)\n",
    "    except ImportError:\n",
    "        if dep == \"hydra\":\n",
    "            dep = \"hydra-core\"\n",
    "        missing_deps.append(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fYO09KGF1AzD"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0dwV0sz1Awv"
   },
   "outputs": [],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
    "roberta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjyBT5SX1Asw"
   },
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoGllgtK1Aqn"
   },
   "outputs": [],
   "source": [
    "pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IZoW-fE71AoV"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "import numpy as np\n",
    "from fairseq.data.data_utils import collate_tokens\n",
    "import heapq\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZkIsZ5m1Al5"
   },
   "outputs": [],
   "source": [
    "actual_task = \"mnli\"\n",
    "dataset = load_dataset(\"glue\", actual_task)\n",
    "metric = load_metric('glue', actual_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8D53xEC1Ajr"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJ8Mv2Ei1W9O"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r0Z4oR-r1gyy"
   },
   "outputs": [],
   "source": [
    "dataset_label_filter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "96TKnWhq1gvT"
   },
   "outputs": [],
   "source": [
    "subset_dev_dataset = []\n",
    "for instance in dataset['train']:\n",
    "    if instance['label'] == dataset_label_filter:\n",
    "        if np.random.rand() < 0.05:\n",
    "          d = {'hypothesis':instance['hypothesis'], 'label':2-instance['label'], 'premise':instance['premise']}\n",
    "          subset_dev_dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lUibtAFp1gsy"
   },
   "outputs": [],
   "source": [
    "target_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18pyKet_3BjX",
    "outputId": "0f550493-6d33-4173-de9c-6be38b9d1de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6572"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzyArCp64YzV"
   },
   "outputs": [],
   "source": [
    "subset_dev_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0sjdM8rLzDB_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9K6MGxn22t9",
    "outputId": "a46f905d-8d14-41f6-f8a2-3e15d24c7455"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULcIGfti22i3"
   },
   "outputs": [],
   "source": [
    "roberta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "vmhkb3HAySjt"
   },
   "outputs": [],
   "source": [
    "def evaluate_batch(model, batch, trigger_token=None):\n",
    "    res_batch = []\n",
    "    for i in range(len(batch[0]['premise']) // 8):\n",
    "      d = {'hypothesis':batch[0]['hypothesis'][8*i:min(8*(i+1), len(batch[0]['hypothesis']))],\n",
    "           'label':batch[0]['label'][8*i:min(8*(i+1), len(batch[0]['label']))],\n",
    "           'premise':batch[0]['premise'][8*i:min(8*(i+1), len(batch[0]['premise']))]}\n",
    "      res_batch.append(d)\n",
    "    length = len(batch[0]['premise'])\n",
    "    del batch\n",
    "\n",
    "\n",
    "    right = 0.\n",
    "    for j in range(len(res_batch)):\n",
    "      sentences = []\n",
    "      for i in range(8):\n",
    "        s = ''\n",
    "        if trigger_token != None:\n",
    "          for k in trigger_token:\n",
    "            s += k\n",
    "          s += ' '\n",
    "        sentences.append([s + res_batch[j]['premise'][i], res_batch[j]['hypothesis'][i]])\n",
    "      sentences = collate_tokens([roberta.encode(sent1, sent2) for sent1, sent2 in sentences], pad_idx=1)\n",
    "      tmp = roberta.predict('mnli', sentences).detach().cpu()\n",
    "      pred = tmp.argmax(axis=1)\n",
    "      for i in range(len(pred)):\n",
    "          right += (pred[i] == res_batch[j]['label'][i])\n",
    "    right /= length\n",
    "    return right.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ezgKlgQ0Mh3",
    "outputId": "2f61a69d-0f67-4f28-b5c7-f98ca36bd357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing :  0.97945833\n"
     ]
    }
   ],
   "source": [
    "for batch in lazy_groups_of(DataLoader(subset_dev_dataset, batch_size=len(subset_dev_dataset)), group_size=1):\n",
    "  print(\"Nothing\", \": \", evaluate_batch(roberta, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSRW0WdPzTP1",
    "outputId": "1b8ea7e8-4cbc-4074-ebdc-de6b334181c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nobody :  0.97671944\n",
      " never :  0.9770237\n",
      " sad :  0.9771759\n",
      " scared :  0.97671944\n",
      " championship :  0.9771759\n"
     ]
    }
   ],
   "source": [
    "trigger_tokens = [' nobody', ' never', ' sad', ' scared', ' championship']\n",
    "for i in trigger_tokens:\n",
    "  for batch in lazy_groups_of(DataLoader(subset_dev_dataset, batch_size=len(subset_dev_dataset)), group_size=1):\n",
    "    print(i, \": \", evaluate_batch(roberta, batch, trigger_token=[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEV_MNSM0VCE",
    "outputId": "d4c0e06c-b522-41df-e5f3-9918734014f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " joyously ,   joyously :  0.97732806\n",
      " joyously ,   anticipating :  0.97458917\n",
      " joyously ,   talented :  0.9786975\n",
      " joyously ,   impress :  0.97808886\n",
      " joyously ,   inspiring :  0.9776324\n",
      " anticipating ,   joyously :  0.9751978\n",
      " anticipating ,   anticipating :  0.97398055\n",
      " anticipating ,   talented :  0.9762629\n",
      " anticipating ,   impress :  0.97656727\n",
      " anticipating ,   inspiring :  0.9759586\n",
      " talented ,   joyously :  0.97458917\n",
      " talented ,   anticipating :  0.97413266\n",
      " talented ,   talented :  0.9764151\n",
      " talented ,   impress :  0.97656727\n",
      " talented ,   inspiring :  0.9758065\n",
      " impress ,   joyously :  0.974437\n",
      " impress ,   anticipating :  0.97458917\n",
      " impress ,   talented :  0.97611076\n",
      " impress ,   impress :  0.97656727\n",
      " impress ,   inspiring :  0.9759586\n",
      " inspiring ,   joyously :  0.97458917\n",
      " inspiring ,   anticipating :  0.9742848\n",
      " inspiring ,   talented :  0.97656727\n",
      " inspiring ,   impress :  0.97671944\n",
      " inspiring ,   inspiring :  0.9764151\n"
     ]
    }
   ],
   "source": [
    "for i in trigger_tokens:\n",
    "  for j in trigger_tokens:\n",
    "    for batch in lazy_groups_of(DataLoader(subset_dev_dataset, batch_size=len(subset_dev_dataset)), group_size=1):\n",
    "      print(i, \", \", j, \": \", evaluate_batch(roberta, batch, trigger_token=[i, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izIufo0f0U-t",
    "outputId": "11904b3b-7f65-429b-fd5d-4a9b02aecfd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anticipating,  impress,  inspiring,  joyously :  0.9762629\n",
      " impress,  joyously,  anticipating,  inspiring :  0.9738284\n",
      " impress,  joyously,  joyously,  anticipating :  0.9703287\n",
      " talented,  impress,  anticipating,  joyously :  0.97534996\n",
      " impress,  joyously,  talented,  joyously :  0.9776324\n",
      " talented,  anticipating,  anticipating,  inspiring :  0.9764151\n",
      " anticipating,  talented,  anticipating,  impress :  0.97611076\n",
      " inspiring,  joyously,  inspiring,  anticipating :  0.9748935\n",
      " talented,  anticipating,  impress,  talented :  0.97534996\n",
      " joyously,  joyously,  anticipating,  joyously :  0.9770237\n",
      " impress,  talented,  talented,  joyously :  0.97854537\n",
      " impress,  inspiring,  talented,  joyously :  0.9764151\n",
      " impress,  joyously,  anticipating,  impress :  0.97458917\n",
      " anticipating,  joyously,  joyously,  anticipating :  0.9704808\n",
      " inspiring,  joyously,  inspiring,  joyously :  0.97732806\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "  tt = []\n",
    "  for j in np.random.choice(5, 4):\n",
    "    tt.append(trigger_tokens[j])\n",
    "  for batch in lazy_groups_of(DataLoader(subset_dev_dataset, batch_size=len(subset_dev_dataset)), group_size=1):\n",
    "    s = tt[0]\n",
    "    for j in tt[1:]:\n",
    "      s += ', ' + j\n",
    "    print(s, \": \", evaluate_batch(roberta, batch, trigger_token=tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97UM_uD37kos"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "stop fast.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
