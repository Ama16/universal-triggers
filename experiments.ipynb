{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "6d7d13b8-91c5-40cb-adca-5610650058bd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  9 15:36:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    74W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC1a2KJEKuBo"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEL020u0-O8",
        "outputId": "20185058-027c-4d05-9e04-4fb4a83a9e64"
      },
      "source": [
        "pip install regex requests"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWfnuPMa1A6G"
      },
      "source": [
        "import functools\n",
        "import importlib\n",
        "from copy import deepcopy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M46ShGdA1A3U",
        "outputId": "d9107ee9-1f1a-41fb-ca18-36f1d7a4229a"
      },
      "source": [
        " pip install hydra-core --upgrade"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: hydra-core in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied, skipping upgrade: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (4.8)\n",
            "Requirement already satisfied, skipping upgrade: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from hydra-core) (2.0.6)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.1.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core) (5.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjyBT5SX1Asw",
        "outputId": "7404acc2-ecc8-48dc-d59b-532dfacf50b0"
      },
      "source": [
        "pip install datasets"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoGllgtK1Aqn",
        "outputId": "5f2ae5a6-5838-4bdf-82c9-fb581eceb9bb"
      },
      "source": [
        "pip install allennlp"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: transformers<4.5,>=4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.4.2)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.0.12)\n",
            "Requirement already satisfied: torch<1.9.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.8.1+cu101)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.7.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.19.5)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.0.0)\n",
            "Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.17.48)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2)\n",
            "Requirement already satisfied: wandb<0.11.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.10.25)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: torchvision<0.10.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.9.1+cu101)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.1.95)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (54.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (20.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.5,>=4.1->allennlp) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.5,>=4.1->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<4.5,>=4.1->allennlp) (3.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.5,>=4.1->allennlp) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.5,>=4.1->allennlp) (0.0.44)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9.0,>=1.6.0->allennlp) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp) (1.0.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.48 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (1.20.48)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.8.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.4)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (2.8.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (0.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (0.4.0)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.5.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (5.4.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (5.0.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (3.1.14)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.11.0,>=0.10.0->allennlp) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.10.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<4.5,>=4.1->allennlp) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.5,>=4.1->allennlp) (2.4.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb<0.11.0,>=0.10.0->allennlp) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.11.0,>=0.10.0->allennlp) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8D53xEC1Ajr",
        "outputId": "55ad2e18-17ba-4d71-b372-80b5036e04fb"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sfwJqaY1A1X"
      },
      "source": [
        "import functools\n",
        "import importlib\n",
        "\n",
        "dependencies = [\n",
        "    \"dataclasses\",\n",
        "    \"hydra\",\n",
        "    \"numpy\",\n",
        "    \"omegaconf\",\n",
        "    \"regex\",\n",
        "    \"requests\",\n",
        "    \"torch\",\n",
        "]\n",
        "\n",
        "missing_deps = []\n",
        "for dep in dependencies:\n",
        "    try:\n",
        "        importlib.import_module(dep)\n",
        "    except ImportError:\n",
        "        if dep == \"hydra\":\n",
        "            dep = \"hydra-core\"\n",
        "        missing_deps.append(dep)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYO09KGF1AzD"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0dwV0sz1Awv",
        "outputId": "6eb70bd9-0d98-4e42-8769-f6670efb6a4e"
      },
      "source": [
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
        "roberta.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaHubInterface(\n",
              "  (model): RobertaModel(\n",
              "    (encoder): RobertaEncoder(\n",
              "      (sentence_encoder): TransformerEncoder(\n",
              "        (dropout_module): FairseqDropout()\n",
              "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (6): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (7): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (8): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (9): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (10): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (11): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (12): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (13): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (14): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (15): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (16): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (17): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (18): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (19): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (20): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (21): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (22): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (23): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (classification_heads): ModuleDict(\n",
              "      (mnli): RobertaClassificationHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZoW-fE71AoV"
      },
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "from allennlp.common.util import lazy_groups_of\n",
        "import numpy as np\n",
        "from fairseq.data.data_utils import collate_tokens\n",
        "import heapq\n",
        "from operator import itemgetter"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZkIsZ5m1Al5",
        "outputId": "53aff3ff-0ac5-416c-b169-208ae7ce0806"
      },
      "source": [
        "actual_task = \"mnli\"\n",
        "dataset = load_dataset(\"glue\", actual_task)\n",
        "metric = load_metric('glue', actual_task)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ8Mv2Ei1W9O"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2-0BI1L1W1H"
      },
      "source": [
        "extracted_grads = []\n",
        "def extract_grad_hook(module, grad_in, grad_out):\n",
        "    extracted_grads.append(grad_out[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq5tcIC51WyM"
      },
      "source": [
        "def add_hooks(language_model):\n",
        "    for module in language_model.modules():\n",
        "        if isinstance(module, torch.nn.Embedding):\n",
        "            print(module.weight.shape[0])\n",
        "            if module.weight.shape[0] == 50265:\n",
        "                module.weight.requires_grad = True\n",
        "                module.register_backward_hook(extract_grad_hook)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlTOZUUq1WwC",
        "outputId": "9a78fc5f-f3bc-4322-f9e7-40bb6a411f46"
      },
      "source": [
        "add_hooks(roberta)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50265\n",
            "514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEexFX151g5D"
      },
      "source": [
        "def get_embedding_weight(language_model):\n",
        "    for module in language_model.modules():\n",
        "        if isinstance(module, torch.nn.Embedding):\n",
        "            if module.weight.shape[0] == 50265:\n",
        "                return module.weight.detach()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPze2ZMV1g15"
      },
      "source": [
        "embedding_weight = get_embedding_weight(roberta)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Z4oR-r1gyy"
      },
      "source": [
        "dataset_label_filter = 0"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96TKnWhq1gvT"
      },
      "source": [
        "#в датасете за логическое следствие отвечает 0, у модели - 2, поэтому поменяем 0 на 2\n",
        "#сохраняем примерно 5% от всех логических следствий в датасете\n",
        "subset_dev_dataset = []\n",
        "for instance in dataset['train']:\n",
        "    if instance['label'] == dataset_label_filter:\n",
        "        if np.random.rand() < 0.05:\n",
        "          d = {'hypothesis':instance['hypothesis'], 'label':2-instance['label'], 'premise':instance['premise']}\n",
        "          subset_dev_dataset.append(d)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUibtAFp1gsy"
      },
      "source": [
        "target_label = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18pyKet_3BjX",
        "outputId": "84426287-2fee-4e64-d226-643816376239"
      },
      "source": [
        "len(subset_dev_dataset)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF0PKIJU1oTt"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.special import softmax"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qNW8Snf1oP7",
        "outputId": "f81e8b7d-025c-4f76-fc14-bd8ad1bd8764"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EauX-MH91oMM",
        "outputId": "2a3cd44f-43a5-4b5d-b7e4-6f229f3acbfb"
      },
      "source": [
        "roberta.to(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaHubInterface(\n",
              "  (model): RobertaModel(\n",
              "    (encoder): RobertaEncoder(\n",
              "      (sentence_encoder): TransformerEncoder(\n",
              "        (dropout_module): FairseqDropout()\n",
              "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
              "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (2): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (3): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (4): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (5): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (6): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (7): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (8): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (9): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (10): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (11): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (12): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (13): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (14): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (15): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (16): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (17): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (18): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (19): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (20): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (21): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (22): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (23): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (dropout_module): FairseqDropout()\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout_module): FairseqDropout()\n",
              "            (activation_dropout_module): FairseqDropout()\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (lm_head): RobertaLMHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (classification_heads): ModuleDict(\n",
              "      (mnli): RobertaClassificationHead(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oalzIRIPftZC"
      },
      "source": [
        "#для оценки лосса на подменяемых таргетах (те на противоречия)\n",
        "def evaluate_batch_on_target(model, batch, trigger_token=None, loss=False):\n",
        "    res_batch = []\n",
        "    for i in range(len(batch[0]['premise']) // 8):\n",
        "      d = {'hypothesis':batch[0]['hypothesis'][8*i:min(8*(i+1), len(batch[0]['hypothesis']))],\n",
        "           'label':[target_label for i in range(min(8*(i+1), len(batch[0]['label'])) - 8*i)],\n",
        "           'premise':batch[0]['premise'][8*i:min(8*(i+1), len(batch[0]['premise']))]}\n",
        "      res_batch.append(d)\n",
        "    length = len(batch[0]['premise'])\n",
        "    del batch\n",
        "\n",
        "\n",
        "    right = 0\n",
        "    loss = 0\n",
        "    for j in range(len(res_batch)):\n",
        "      sentences = []\n",
        "      for i in range(8):\n",
        "        s = ''\n",
        "        for k in trigger_token:\n",
        "          s += k\n",
        "        s += ' '\n",
        "        sentences.append([s + res_batch[j]['premise'][i], res_batch[j]['hypothesis'][i]])\n",
        "      sentences = collate_tokens([roberta.encode(sent1, sent2) for sent1, sent2 in sentences], pad_idx=1)\n",
        "      tmp = roberta.predict('mnli', sentences).detach().cpu()\n",
        "      pred = tmp.argmax(axis=1)\n",
        "      for i in range(len(pred)):\n",
        "          right += (pred[i] == target_label)\n",
        "      m = torch.nn.Softmax()\n",
        "      for i in range(len(pred)):\n",
        "          now = m(tmp[i])\n",
        "          loss -= torch.log(now[target_label])\n",
        "    loss = loss / length\n",
        "    return right.detach().cpu().numpy(), loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm4ipHf61w04"
      },
      "source": [
        "def evaluate_batch(model, batch, trigger_token=None, loss=False):\n",
        "    if trigger_token is None:\n",
        "        right = 0\n",
        "        sentences = []\n",
        "        for i in range(len(batch[0]['premise'])):\n",
        "          sentences.append([batch[0]['premise'][i], batch[0]['hypothesis'][i]])\n",
        "        sentences = collate_tokens([roberta.encode(sent1, sent2) for sent1, sent2 in sentences], pad_idx=1)\n",
        "        pred = roberta.predict('mnli', sentences).argmax(axis=1)\n",
        "        for i in range(len(pred)):\n",
        "            right += (pred[i] == batch[0]['label'][i])\n",
        "        return right.detach().cpu().numpy(), _\n",
        "    else:\n",
        "        right = 0\n",
        "        sentences = []\n",
        "        for i in range(len(batch[0]['premise'])):\n",
        "          s = ''\n",
        "          for k in trigger_token:\n",
        "            s += k\n",
        "          s += ' '\n",
        "          sentences.append([s + batch[0]['premise'][i], batch[0]['hypothesis'][i]])\n",
        "        sentences = collate_tokens([roberta.encode(sent1, sent2) for sent1, sent2 in sentences], pad_idx=1)\n",
        "        tmp = roberta.predict('mnli', sentences)\n",
        "        pred = tmp.argmax(axis=1)\n",
        "        for i in range(len(pred)):\n",
        "            right += (pred[i] == batch[0]['label'][i])\n",
        "        if loss:\n",
        "            loss = 0\n",
        "            m = torch.nn.Softmax()\n",
        "            for i in range(len(pred)):\n",
        "                now = m(tmp[i])\n",
        "                loss -= torch.log(now[batch[0]['label'][i]])\n",
        "            loss = loss / len(pred)\n",
        "            return right.detach().cpu().numpy(), loss\n",
        "        return right.detach().cpu().numpy(), _"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKzs7iq31wvQ"
      },
      "source": [
        "def get_accuracy(model, dev_dataset, trigger_token=None, loss=False):\n",
        "  if trigger_token is None:\n",
        "      res = 0\n",
        "      for batch in lazy_groups_of(DataLoader(dev_dataset, batch_size=8, shuffle=False), group_size=1):\n",
        "          res += evaluate_batch(model, batch, trigger_token, loss)[0]\n",
        "      print(\"Without Triggers: \" + str(res / len(dev_dataset)))\n",
        "  else:\n",
        "      res = 0\n",
        "      for batch in lazy_groups_of(DataLoader(dev_dataset, batch_size=8, shuffle=False), group_size=1):\n",
        "          res += evaluate_batch(model, batch, trigger_token, loss)[0]\n",
        "      s = ''\n",
        "      for k in trigger_token:\n",
        "        s += k + ' '\n",
        "      print(\"Current Triggers: \" + s + \" : \" + str(res / len(dev_dataset)))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GMhRt9_Kelv"
      },
      "source": [
        "def get_average_grad(model, batch, trigger_token, target_label=None):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    original_labels = batch[0]['label'].clone()\n",
        "\n",
        "    if target_label is not None:\n",
        "        batch[0]['label'] = int(target_label) * torch.ones_like(batch[0]['label']).cuda()\n",
        "\n",
        "    global extracted_grads\n",
        "    res_batch = []\n",
        "    for i in range(len(batch[0]['premise']) // 8):\n",
        "      d = {'hypothesis':batch[0]['hypothesis'][8*i:min(8*(i+1), len(batch[0]['hypothesis']))],\n",
        "           'label':batch[0]['label'][8*i:min(8*(i+1), len(batch[0]['label']))],\n",
        "           'premise':batch[0]['premise'][8*i:min(8*(i+1), len(batch[0]['premise']))]}\n",
        "      res_batch.append(d)\n",
        "    \n",
        "    averaged_grad = None\n",
        "    for i in res_batch:\n",
        "        optimizer.zero_grad()\n",
        "        extracted_grads = [] \n",
        "        loss = evaluate_batch(model, [i], trigger_token, True)[1]\n",
        "        loss.backward()\n",
        "\n",
        "        grads = extracted_grads[0].cpu()\n",
        "        if averaged_grad is None:\n",
        "          averaged_grad = torch.sum(grads, dim=0)[:4]\n",
        "        else:\n",
        "          averaged_grad += torch.sum(grads, dim=0)[:4]\n",
        "    batch[0]['label'] = original_labels \n",
        "    \n",
        "    return averaged_grad"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zySRjmQyBEaD"
      },
      "source": [
        "def hotflip_attack(averaged_grad, embedding_matrix, trigger_token, num_candidates=1):\n",
        "    averaged_grad = averaged_grad.cpu()\n",
        "    embedding_matrix = embedding_matrix.cpu()\n",
        "\n",
        "    averaged_grad = averaged_grad.unsqueeze(0)\n",
        "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
        "                                                 (averaged_grad, embedding_matrix))            \n",
        "    \n",
        "    gradient_dot_embedding_matrix *= -1  \n",
        "\n",
        "    _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
        "    return best_k_ids.detach().cpu().numpy()[0]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCLNBGewEW96"
      },
      "source": [
        "def get_loss_per_candidate(index, model, batch, trigger_token, cand_trigger_token):\n",
        "    loss_per_candidate = []\n",
        "    curr_loss = evaluate_batch_on_target(model, batch, trigger_token, True)[1].cpu().detach().numpy()\n",
        "    loss_per_candidate.append((deepcopy(trigger_token), curr_loss))\n",
        "    for cand_id in range(len(cand_trigger_token[index])):\n",
        "        trigger_token_one_replaced = deepcopy(trigger_token) \n",
        "        trigger_token_one_replaced[index] = cand_trigger_token[index][cand_id]\n",
        "        loss = evaluate_batch_on_target(model, batch, trigger_token_one_replaced, True)[1].cpu().detach().numpy()\n",
        "        loss_per_candidate.append((deepcopy(trigger_token_one_replaced), loss))\n",
        "    return loss_per_candidate"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX9-i45ZEEC4"
      },
      "source": [
        "def get_best_candidates(model, batch, trigger_token, cand_trigger_token, beam_size=1):\n",
        "    loss_per_candidate = get_loss_per_candidate(0, model, batch, trigger_token,\n",
        "                                                cand_trigger_token)\n",
        "\n",
        "    top_candidates = heapq.nsmallest(beam_size, loss_per_candidate, key=itemgetter(1))\n",
        "\n",
        "    for idx in range(1, len(trigger_token)):\n",
        "        loss_per_candidate = []\n",
        "        for cand, _ in top_candidates:\n",
        "            loss_per_candidate.extend(get_loss_per_candidate(idx, model, batch, cand,\n",
        "                                                             cand_trigger_token))\n",
        "        top_candidates = heapq.nsmallest(beam_size, loss_per_candidate, key=itemgetter(1))\n",
        "    return min(top_candidates, key=itemgetter(1))[0]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IalxNVGEMrp0",
        "outputId": "e4ce918b-cce8-4229-be52-f687cd8887cb"
      },
      "source": [
        "get_accuracy(roberta, subset_dev_dataset)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Triggers: 0.9792738275340394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIAi8z_wKoQF"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyaWvfSc1wiF",
        "outputId": "623c814f-3a3e-46de-8809-b238bdc50fb5"
      },
      "source": [
        "trigger_token = ['Not', ' means', ' opposite', ' the'] \n",
        "for epoch in range(1):\n",
        "    for batch in lazy_groups_of(DataLoader(subset_dev_dataset, batch_size=len(subset_dev_dataset)//12, shuffle=True), group_size=1):\n",
        "        get_accuracy(roberta, subset_dev_dataset, trigger_token)\n",
        "        \n",
        "        roberta.train() \n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "\n",
        "        averaged_grad = get_average_grad(roberta, batch, trigger_token, target_label)\n",
        "\n",
        "        cand_trigger_token_ids = hotflip_attack(averaged_grad,\n",
        "                                                        embedding_weight,\n",
        "                                                        trigger_token,\n",
        "                                                        num_candidates=3)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        cand_trigger_token = []\n",
        "        for k in range(4):\n",
        "          tmp = []\n",
        "          for j in range(len(cand_trigger_token_ids[k])):\n",
        "            tmp.append(tokenizer1.decode(int(cand_trigger_token_ids[k][j])))\n",
        "          cand_trigger_token.append(tmp)\n",
        "\n",
        "          trigger_token[k] = cand_trigger_token[k][0]\n",
        "\n",
        "          print(\"Претенденты на место \", k, \": \", cand_trigger_token[k])\n",
        "        \n",
        "\n",
        "        trigger_token = get_best_candidates(roberta,\n",
        "                                                  batch,\n",
        "                                                  trigger_token,\n",
        "                                                  cand_trigger_token)\n",
        "\n",
        "        torch.cuda.empty_cache()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Triggers: Not  means  opposite  the  : 0.9747352496217851\n",
            "Претенденты на место  0 :  ['aul', ' Tul', 'thia']\n",
            "Претенденты на место  1 :  ['Answer', 'BUT', 'Used']\n",
            "Претенденты на место  2 :  [' signifies', 'asca', ' �']\n",
            "Претенденты на место  3 :  [' mapping', ' marrying', ' dressing']\n",
            "Current Triggers: thia BUT  �  marrying  : 0.9633888048411497\n",
            "Претенденты на место  0 :  [' Derek', ' arts', ' Shaw']\n",
            "Претенденты на место  1 :  ['emate', ' Choi', ' Gerrard']\n",
            "Претенденты на место  2 :  ['hirt', 'URN', ' dissolve']\n",
            "Претенденты на место  3 :  ['iture', 'ilst', 'ucci']\n",
            "Current Triggers:  Shaw  Gerrard hirt ilst  : 0.9635400907715582\n",
            "Претенденты на место  0 :  ['ama', 'ocy', ' Rodgers']\n",
            "Претенденты на место  1 :  [' BB', ' Kak', ' ONLY']\n",
            "Претенденты на место  2 :  ['seys', ' Beckham', 'Football']\n",
            "Претенденты на место  3 :  ['�', '�', ' wink']\n",
            "Current Triggers: ocy  ONLY seys �  : 0.9649016641452345\n",
            "Претенденты на место  0 :  ['imation', ' reactor', ' Molecular']\n",
            "Претенденты на место  1 :  [' intakes', ' breaths', ' harness']\n",
            "Претенденты на место  2 :  ['only', 'Only', 'LESS']\n",
            "Претенденты на место  3 :  ['Campaign', 'Meet', 'Contribut']\n",
            "Current Triggers: imation  harness only Campaign  : 0.9636913767019667\n",
            "Претенденты на место  0 :  [' mM', ' volts', ' potassium']\n",
            "Претенденты на место  1 :  [' JP', ' REALLY', ' Cla']\n",
            "Претенденты на место  2 :  [' schizophren', ' visceral', ' repressive']\n",
            "Претенденты на место  3 :  [' \"…', '�', ' Surely']\n",
            "Current Triggers:  mM  REALLY  schizophren  \"…  : 0.9673222390317701\n",
            "Претенденты на место  0 :  [' privatization', ' viewership', ' popularity']\n",
            "Претенденты на место  1 :  [' DAM', ' Cah', ' ellipt']\n",
            "Претенденты на место  2 :  [' WILL', ' BE', ' SAY']\n",
            "Претенденты на место  3 :  ['pta', 'gewater', 'vir']\n",
            "Current Triggers:  popularity  ellipt  SAY gewater  : 0.9639939485627836\n",
            "Претенденты на место  0 :  [' collagen', ' yeast', ' tour']\n",
            "Претенденты на место  1 :  ['iggs', 'elson', ' Ratt']\n",
            "Претенденты на место  2 :  ['worm', ' worm', 'target']\n",
            "Претенденты на место  3 :  [' livestream', ' subdu', ' outweigh']\n",
            "Current Triggers:  collagen  Ratt  worm  outweigh  : 0.9633888048411497\n",
            "Претенденты на место  0 :  [' concentrations', ' formulations', ' concentration']\n",
            "Претенденты на место  1 :  [' physi', ' worms', ' gelatin']\n",
            "Претенденты на место  2 :  [' Liqu', ' Municip', ' �']\n",
            "Претенденты на место  3 :  [' worms', ' pathological', ' diarrhea']\n",
            "Current Triggers:  formulations  physi  Liqu  worms  : 0.9652042360060514\n",
            "Претенденты на место  0 :  ['mt', 'ér', 'icol']\n",
            "Претенденты на место  1 :  [' Kur', ' Sir', ' blob']\n",
            "Претенденты на место  2 :  ['urally', ' clinically', ' biologically']\n",
            "Претенденты на место  3 :  [' Bellev', ' Schn', ' Zhao']\n",
            "Current Triggers: icol  Sir  biologically  Bellev  : 0.9617246596066565\n",
            "Претенденты на место  0 :  [' breakout', ' significance', ' Plastic']\n",
            "Претенденты на место  1 :  ['inx', 'enario', 'iologist']\n",
            "Претенденты на место  2 :  ['Sir', 'proxy', 'Lord']\n",
            "Претенденты на место  3 :  [' Phys', ' physi', 'Phys']\n",
            "Current Triggers:  significance inx Sir  physi  : 0.9630862329803328\n",
            "Претенденты на место  0 :  ['que', 'au', 'ain']\n",
            "Претенденты на место  1 :  [' catalogue', ' dissertation', ' optimum']\n",
            "Претенденты на место  2 :  [' impair', ' proble', ' discredit']\n",
            "Претенденты на место  3 :  [' pity', ' observe', ' Sir']\n",
            "Current Triggers: au  optimum  discredit  pity  : 0.9677760968229955\n",
            "Претенденты на место  0 :  [' aston', 'iour', ' overwrite']\n",
            "Претенденты на место  1 :  [' Cheong', ' Lau', ' Archive']\n",
            "Претенденты на место  2 :  [' SUPPORT', ' SHA', ' SPL']\n",
            "Претенденты на место  3 :  [' Chattanooga', 'iddler', ' Jakarta']\n",
            "Current Triggers: iour  Lau  SUPPORT  Chattanooga  : 0.9673222390317701\n",
            "Претенденты на место  0 :  [' HIM', ' guardian', ' LEG']\n",
            "Претенденты на место  1 :  ['Daddy', 'Mario', 'Disney']\n",
            "Претенденты на место  2 :  ['squ', ' sn', 'oyle']\n",
            "Претенденты на место  3 :  [' hindsight', ' mercury', ' immortality']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ThdiSIzqDoK",
        "outputId": "9c59122e-40fe-4441-ec9e-1680a810b93d"
      },
      "source": [
        "get_accuracy(roberta, subset_dev_dataset, trigger_token)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Triggers:  guardian Daddy squ  hindsight  : 0.967624810892587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNAyoasXthWR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}